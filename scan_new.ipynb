{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pefile\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from collections import Counter\n",
    "import pywt\n",
    "from scipy import stats\n",
    "from secrets import randbits\n",
    "class EnhancedFeatureExtractor:\n",
    "    def __init__(self, wavelet='db1', level=3):\n",
    "        self.wavelet = wavelet\n",
    "        self.level = level\n",
    "        # 预计算特征维度\n",
    "        self.expected_feature_dim = self._calculate_expected_dim()\n",
    "        \n",
    "    def _calculate_expected_dim(self):\n",
    "        \"\"\"计算预期的特征维度\"\"\"\n",
    "        pe_features = 8  # 文件熵(1) + 节特征(3) + 导出表特征(4)\n",
    "        \n",
    "        # 小波特征维度\n",
    "        # 对于每个分解级别，有3个细节系数矩阵(水平、垂直、对角线)\n",
    "        # 每个矩阵提供4个统计量(均值、标准差、偏度、峰度)\n",
    "        wavelet_features = 4  # 近似系数的4个统计量\n",
    "        wavelet_features += 3 * 4 * self.level  # 细节系数的统计量\n",
    "        \n",
    "        return pe_features + wavelet_features\n",
    "    def extract_export_features(self, pe):\n",
    "        \"\"\"提取导出表特征\"\"\"\n",
    "        features = []\n",
    "        try:\n",
    "            if hasattr(pe, 'DIRECTORY_ENTRY_EXPORT'):\n",
    "                exports = pe.DIRECTORY_ENTRY_EXPORT.symbols\n",
    "                num_exports = len(exports) if exports else 0\n",
    "                features.extend([\n",
    "                    num_exports,\n",
    "                    len(pe.DIRECTORY_ENTRY_EXPORT.name) if hasattr(pe.DIRECTORY_ENTRY_EXPORT, 'name') else 0,\n",
    "                    sum(1 for e in exports if e.name) if exports else 0,\n",
    "                    pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT']].Size\n",
    "                ])\n",
    "            else:\n",
    "                features.extend([0] * 4)\n",
    "        except:\n",
    "            features.extend([0] * 4)\n",
    "    \n",
    "        # 确保返回4个特征\n",
    "        return features[:4] if len(features) >=4 else features + [0]*(4-len(features))\n",
    "    def calculate_entropy(self, data):\n",
    "        \"\"\"计算数据的熵值\"\"\"\n",
    "        if not data:\n",
    "            return 0\n",
    "        \n",
    "        occurrences = Counter(data)\n",
    "        total_bytes = len(data)\n",
    "        entropy = 0\n",
    "        \n",
    "        # Shannon熵\n",
    "        for count in occurrences.values():\n",
    "            probability = count / total_bytes\n",
    "            entropy -= probability * math.log2(probability)\n",
    "            \n",
    "        return entropy\n",
    "    def extract_section_features(self, pe):\n",
    "        \"\"\"提取固定数量的节特征\"\"\"\n",
    "        features = []\n",
    "        try:\n",
    "            if hasattr(pe, 'sections') and len(pe.sections) > 0:\n",
    "                section = pe.sections[0]  # 只使用第一个节\n",
    "                section_data = section.get_data()\n",
    "                features.extend([\n",
    "                    len(section_data),\n",
    "                    self.calculate_entropy(section_data),\n",
    "                    section.Characteristics,\n",
    "                ])\n",
    "            else:\n",
    "                features.extend([0] * 3)\n",
    "        except:\n",
    "            features.extend([0] * 3)\n",
    "        return features\n",
    "\n",
    "    def extract_wavelet_features(self, image_array):\n",
    "        \"\"\"提取固定维度的小波特征\"\"\"\n",
    "        try:\n",
    "            coeffs = pywt.wavedec2(image_array, self.wavelet, level=self.level)\n",
    "            features = []\n",
    "            \n",
    "            features.extend([\n",
    "                np.mean(coeffs[0]),\n",
    "                np.std(coeffs[0]),\n",
    "                stats.skew(coeffs[0].ravel()),\n",
    "                stats.kurtosis(coeffs[0].ravel())\n",
    "            ])\n",
    "            \n",
    "            for detail_coeffs in coeffs[1:]:\n",
    "                for detail in detail_coeffs:\n",
    "                    features.extend([\n",
    "                        np.mean(detail),\n",
    "                        np.std(detail),\n",
    "                        stats.skew(detail.ravel()),\n",
    "                        stats.kurtosis(detail.ravel())\n",
    "                    ])\n",
    "            \n",
    "            # 确保特征维度正确\n",
    "            expected_wavelet_features = 4 + (3 * 4 * self.level)\n",
    "            if len(features) < expected_wavelet_features:\n",
    "                features.extend([0] * (expected_wavelet_features - len(features)))\n",
    "            elif len(features) > expected_wavelet_features:\n",
    "                features = features[:expected_wavelet_features]\n",
    "                \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            print(f\"Error in wavelet feature extraction: {str(e)}\")\n",
    "            return [0] * (4 + (3 * 4 * self.level))\n",
    "\n",
    "    def extract_features(self, file_path):\n",
    "        \"\"\"提取固定维度的特征集\"\"\"\n",
    "        try:\n",
    "            features = []\n",
    "            \n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = f.read()\n",
    "            \n",
    "            # 1. 熵\n",
    "            file_entropy = self.calculate_entropy(data)\n",
    "            features.append(file_entropy)\n",
    "            \n",
    "            # 2. PE特征\n",
    "            try:\n",
    "                pe = pefile.PE(file_path)\n",
    "                features.extend(self.extract_section_features(pe))\n",
    "                features.extend(self.extract_export_features(pe))\n",
    "            except:\n",
    "                features.extend([0] * 7)  # PE特征的默认值\n",
    "            \n",
    "            # 3. 小波特征\n",
    "            image_array = np.frombuffer(data, dtype=np.uint8)\n",
    "            width = 384\n",
    "            height = len(image_array) // width + (1 if len(image_array) % width else 0)\n",
    "            padded_size = height * width\n",
    "            \n",
    "            if len(image_array) < padded_size:\n",
    "                image_array = np.pad(image_array, (0, padded_size - len(image_array)))\n",
    "            \n",
    "            image_array = image_array.reshape((height, width))\n",
    "            wavelet_features = self.extract_wavelet_features(image_array)\n",
    "            features.extend(wavelet_features)\n",
    "            \n",
    "            # 确保特征维度正确\n",
    "            if len(features) != self.expected_feature_dim:\n",
    "                print(f\"Warning: Feature dimension mismatch for {file_path}\")\n",
    "                if len(features) < self.expected_feature_dim:\n",
    "                    features.extend([0] * (self.expected_feature_dim - len(features)))\n",
    "                else:\n",
    "                    features = features[:self.expected_feature_dim]\n",
    "            \n",
    "            return np.array(features, dtype=np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features from {file_path}: {str(e)}\")\n",
    "            return np.zeros(self.expected_feature_dim, dtype=np.float32)\n",
    "\n",
    "class EnhancedMalwareDetector(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(EnhancedMalwareDetector, self).__init__()\n",
    "        \n",
    "        self.pe_features = nn.Sequential(\n",
    "            nn.Linear(8, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        wavelet_feature_size = input_size - 8\n",
    "        self.wavelet_features = nn.Sequential(\n",
    "            nn.Linear(wavelet_feature_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(96, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "        \n",
    "        self.attention_pe = nn.Sequential(\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_wavelet = nn.Sequential(\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pe_x = x[:, :8]\n",
    "        wavelet_x = x[:, 8:]\n",
    "        \n",
    "        pe_features = self.pe_features(pe_x)\n",
    "        pe_attention = self.attention_pe(pe_features)\n",
    "        pe_features = pe_features * pe_attention\n",
    "        \n",
    "        wavelet_features = self.wavelet_features(wavelet_x)\n",
    "        wavelet_attention = self.attention_wavelet(wavelet_features)\n",
    "        wavelet_features = wavelet_features * wavelet_attention\n",
    "        \n",
    "        combined_features = torch.cat((pe_features, wavelet_features), dim=1)\n",
    "        fused_features = self.fusion(combined_features)\n",
    "        \n",
    "        output = self.classifier(fused_features)\n",
    "        return output\n",
    "\n",
    "def load_model(model_path, device):\n",
    "    \"\"\"加载训练好的模型\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = EnhancedMalwareDetector(checkpoint['input_size']).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def convert_pe_to_image(file_path, width=384):\n",
    "    \"\"\"将PE文件转换为灰度图像\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        byte_array = np.frombuffer(content, dtype=np.uint8)\n",
    "        height = len(byte_array) // width + (1 if len(byte_array) % width else 0)\n",
    "        padded_size = height * width\n",
    "        if len(byte_array) < padded_size:\n",
    "            byte_array = np.pad(byte_array, (0, padded_size - len(byte_array)))\n",
    "        \n",
    "        image_array = byte_array.reshape((height, width))\n",
    "        image = Image.fromarray(image_array)\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {file_path} to image: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_wavelet_features(image_array, wavelet='haar', level=3):\n",
    "    \"\"\"提取小波特征\"\"\"\n",
    "    coeffs = pywt.wavedec2(image_array, wavelet, level=level)\n",
    "    features = []\n",
    "    features.extend([\n",
    "        np.mean(coeffs[0]),\n",
    "        np.std(coeffs[0]),\n",
    "        stats.skew(coeffs[0].ravel()),\n",
    "        stats.kurtosis(coeffs[0].ravel())\n",
    "    ])\n",
    "    for detail_coeffs in coeffs[1:]:\n",
    "        for detail in detail_coeffs:\n",
    "            features.extend([\n",
    "                np.mean(detail),\n",
    "                np.std(detail),\n",
    "                stats.skew(detail.ravel()),\n",
    "                stats.kurtosis(detail.ravel())\n",
    "            ])\n",
    "    return np.array(features)\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"提取文件的特征集\"\"\"\n",
    "    features = []\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = f.read()\n",
    "        \n",
    "        # 计算文件熵\n",
    "        file_entropy = EnhancedFeatureExtractor().calculate_entropy(data)\n",
    "        features.append(file_entropy)\n",
    "        try:\n",
    "            # 提取PE特征\n",
    "            pe = pefile.PE(file_path)\n",
    "            features.extend(EnhancedFeatureExtractor().extract_section_features(pe))\n",
    "            features.extend(EnhancedFeatureExtractor().extract_export_features(pe))\n",
    "        except:\n",
    "            features.extend([0] * 7)\n",
    "        # 将文件转换为图像并提取小波特征\n",
    "        image = convert_pe_to_image(file_path)\n",
    "        if image is not None:\n",
    "            image_array = np.array(image)\n",
    "            wavelet_features = extract_wavelet_features(image_array)\n",
    "            features.extend(wavelet_features)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(f\"Error extracting features from {file_path}: {str(e)}\")\n",
    "        pass\n",
    "    return np.array(features)\n",
    "\n",
    "def scan_directory(model_path, scan_dir, device):\n",
    "    \"\"\"扫描指定目录下的文件\"\"\"\n",
    "    model = load_model(model_path, device)\n",
    "    results = []\n",
    "    total_files = 0\n",
    "    detected_malware = 0\n",
    "    \n",
    "    for filename in os.listdir(scan_dir):\n",
    "        file_path = os.path.join(scan_dir, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            total_files += 1\n",
    "            features = extract_features(file_path)\n",
    "            if features is not None:\n",
    "                features_tensor = torch.FloatTensor(features).unsqueeze(0).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(features_tensor)\n",
    "                    probs = F.softmax(outputs, dim=1)\n",
    "                    malware_score = probs[0][1].item()\n",
    "                    prediction = 1 if malware_score > 0.85 else 0  # 阈值不建议低于0.75,否则误报率会很高\n",
    "                \n",
    "                results.append({\n",
    "                    'file': filename,\n",
    "                    'is_malware': bool(prediction),\n",
    "                    'malware_score': malware_score\n",
    "                })\n",
    "                \n",
    "                if prediction == 1:\n",
    "                    detected_malware += 1\n",
    "    \n",
    "    detection_rate = (detected_malware / total_files * 100) if total_files > 0 else 0\n",
    "    print(f\"Total files scanned: {total_files}\")\n",
    "    print(f\"Detected malware: {detected_malware}\")\n",
    "    print(f\"Detection rate: {detection_rate:.2f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files scanned: 7\n",
      "Detected malware: 5\n",
      "Detection rate: 71.43%\n",
      "File: Gx7.exe, Is Malware: True, Malware Score: 0.9758\n",
      "File: msncore.dll, Is Malware: False, Malware Score: 0.6013\n",
      "File: .DS_Store, Is Malware: False, Malware Score: 0.2438\n",
      "File: mal5.exe, Is Malware: True, Malware Score: 0.8855\n",
      "File: mal4.exe, Is Malware: True, Malware Score: 0.8589\n",
      "File: mal3.exe, Is Malware: True, Malware Score: 0.9773\n",
      "File: mal1.exe, Is Malware: True, Malware Score: 0.8777\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/best_model.pth\"\n",
    "scan_dir = \"scan_files\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "results = scan_directory(model_path, scan_dir, device)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"File: {result['file']}, Is Malware: {result['is_malware']}, Malware Score: {result['malware_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
